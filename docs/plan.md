# 개발 계획 (Development Plan)

## 프로젝트 개요

**프로젝트명**: 시스템 리소스 메트릭 모니터링 시스템
**목표**: CPU, 메모리, 디스크, 네트워크 메트릭을 실시간으로 수집, 저장, 시각화하고 알림을 제공하는 서버 모니터링 시스템 개발
**기간**: 10주 (Phase 1-3)
**시작일**: TBD

---

## Phase 1: MVP (4주)

### 목표
기본적인 메트릭 수집, 저장, 조회 기능을 갖춘 최소 기능 제품(MVP) 개발

### Week 1-2: 메트릭 수집기 개발 ✅ **완료**
- **Week 1** ✅
  - [x] 프로젝트 구조 설정 및 환경 구성
  - [x] psutil 기반 CPU 메트릭 수집 모듈 개발
    - CPU 전체 사용률
    - CPU 코어별 사용률
    - 로드 평균 (1m, 5m, 15m)
  - [x] 메모리 메트릭 수집 모듈 개발
    - 총 메모리, 사용 중, 사용 가능
    - 메모리 사용률 (%)
    - Swap 메모리 정보
  - [x] 수집기 설정 파일 구조 정의 (YAML)
  - [x] **추가 완료**: 디스크 메트릭 수집 모듈 (원래 Week 5-6 계획)
  - [x] **추가 완료**: 네트워크 메트릭 수집 모듈 (원래 Week 5-6 계획)

- **Week 2** ✅
  - [x] 메트릭 수집 스케줄러 구현 (5초 간격)
  - [x] HTTPS API 전송 모듈 개발
  - [x] 네트워크 장애 대비 로컬 버퍼링 구현
  - [x] 수집기 단위 테스트 작성
  - [ ] 수집기 성능 검증 (< 5% CPU, < 100MB 메모리) - **테스트 필요**

**완료된 파일**:
- `collector/src/main.py` - 메인 진입점, 스케줄러, 시그널 핸들링
- `collector/src/metrics_collector.py` - 모든 메트릭 수집 로직
- `collector/src/config.py` - YAML 설정 로더, 환경변수 지원
- `collector/src/metrics_sender.py` - API 전송, 로컬 버퍼링
- `collector/tests/test_metrics_collector.py` - 단위 테스트
- `collector/config/collector-config.yaml` - 설정 템플릿
- `collector/requirements.txt` - Python 의존성

### Week 3: API 서버 및 데이터베이스 연동
- [ ] FastAPI 프로젝트 구조 설정
- [ ] InfluxDB 2.x 설치 및 스키마 정의
- [ ] PostgreSQL 설치 및 메타데이터 테이블 설계
- [ ] 메트릭 수집 엔드포인트 구현 (`POST /api/v1/metrics/collect`)
- [ ] 현재 메트릭 조회 엔드포인트 (`GET /api/v1/metrics/current`)
- [ ] 시계열 데이터 조회 엔드포인트 (`GET /api/v1/metrics/history`)
- [ ] JWT/API Key 인증 미들웨어 구현
- [ ] Rate Limiting 구현 (100 req/min per collector)
- [ ] API 엔드포인트 테스트 작성

### Week 4: 기본 대시보드 및 알림 기능
- [ ] Grafana 설치 및 InfluxDB 데이터소스 연결
- [ ] CPU 메트릭 대시보드 패널 생성
- [ ] 메모리 메트릭 대시보드 패널 생성
- [ ] 개요(Overview) 대시보드 생성
- [ ] 10초 자동 새로고침 설정
- [ ] Alert Manager 기본 구조 구현
- [ ] 임계값 기반 알림 평가 엔진 개발
- [ ] 기본 알림 규칙 정의 (CPU > 80%, 메모리 > 85%)
- [ ] Slack 알림 채널 연동
- [ ] 알림 중복 제거 로직 구현 (5분)
- [ ] MVP 통합 테스트

**Milestone**: MVP 데모 가능 - CPU/메모리 모니터링 및 알림

---

## Phase 2: 기능 확장 (4주)

### 목표
디스크 및 네트워크 메트릭 추가, 고급 알림 기능 구현

### Week 5-6: 디스크 및 네트워크 메트릭 추가 ✅ **선행 완료 (Week 1-2에서)**
- **Week 5: 디스크 메트릭** ✅ **완료 (Week 1-2)**
  - [x] 디스크 사용량 메트릭 수집 모듈 (30초 간격)
    - 전체/사용/여유 공간 및 사용률
    - 장치별 메트릭
  - [x] 디스크 I/O 메트릭 수집 모듈 (5초 간격)
    - Read/Write 처리량 (bytes/sec)
    - IOPS (read/write count)
  - [x] Inode 사용률 메트릭 수집
  - [ ] 디스크 메트릭 API 엔드포인트 구현 - **Week 3 예정**
  - [ ] 디스크 대시보드 패널 생성 - **Week 4 예정**
  - [x] 디스크 메트릭 단위 테스트

- **Week 6: 네트워크 메트릭** ✅ **완료 (Week 1-2)**
  - [x] 네트워크 I/O 메트릭 수집 모듈 (5초 간격)
    - 송수신 바이트 및 패킷
    - 에러 및 드롭 카운트
  - [x] 네트워크 연결 상태 메트릭 (TCP/UDP)
  - [x] 인터페이스별 메트릭 수집 설정
  - [ ] 네트워크 메트릭 API 엔드포인트 구현 - **Week 3 예정**
  - [ ] 네트워크 대시보드 패널 생성 - **Week 4 예정**
  - [x] 네트워크 메트릭 단위 테스트

**노트**:
- Collector 수준의 디스크/네트워크 메트릭 수집은 Week 1-2에 완료됨
- API 엔드포인트와 대시보드 패널은 해당 컴포넌트 개발 시점에 추가 예정
- **일정 절감**: Week 5-6을 다른 작업에 할당 가능

### Week 7: 고급 알림 규칙
- [ ] 알림 규칙 CRUD API 구현 (`POST/GET/PUT/DELETE /api/v1/alerts/rules`)
- [ ] 알림 이력 조회 API (`GET /api/v1/alerts`)
- [ ] 복합 조건 알림 규칙 지원 (AND/OR)
- [ ] 시간 기반 알림 임계값 (예: 5분간 지속)
- [ ] 알림 심각도 레벨 구현 (WARNING/CRITICAL)
- [ ] Email 알림 채널 연동 (SMTP)
- [ ] Webhook 알림 채널 구현
- [ ] 알림 규칙 설정 UI (Grafana 또는 커스텀)
- [ ] 디스크 및 네트워크 알림 규칙 추가
- [ ] 알림 테스트 스위트 작성

### Week 8: 대시보드 개선
- [ ] 대시보드 시간 범위 선택 기능 (1h, 6h, 24h, 7d, 30d)
- [ ] 대시보드 레이아웃 최적화
- [ ] 메트릭 비교 및 상관관계 패널 추가
- [ ] 알림 이력 표시 패널 추가
- [ ] 대시보드 로딩 성능 최적화 (< 2초)
- [ ] 모바일 반응형 디자인 적용
- [ ] 대시보드 템플릿 변수 설정 (호스트 선택)

**Milestone**: 전체 메트릭 모니터링 및 고급 알림 시스템 완성

---

## Phase 3: 최적화 및 배포 준비 (2주)

### 목표
성능 튜닝, 안정성 개선, 프로덕션 배포 준비

### Week 9: 성능 튜닝 및 테스트
- [ ] 수집기 성능 프로파일링 및 최적화
- [ ] API 서버 쿼리 성능 최적화
  - InfluxDB 쿼리 최적화
  - 인덱싱 및 캐싱 전략
- [ ] 데이터 다운샘플링 구현
  - 5초 → 1분 평균 (보관 7일)
  - 1분 → 5분 평균 (보관 30일)
- [ ] 부하 테스트 (100개 이상 동시 수집기)
- [ ] API 응답 시간 검증
  - 현재 메트릭: < 200ms
  - 24시간 시계열: < 1초
- [ ] 메모리 누수 및 리소스 관리 점검
- [ ] 통합 테스트 및 E2E 테스트 작성
- [ ] 장애 시나리오 테스트 (네트워크 단절, DB 장애 등)

### Week 10: 문서화 및 배포 자동화
- [ ] API 문서 작성 (OpenAPI/Swagger)
- [ ] 수집기 설치 및 설정 가이드 작성
- [ ] 운영 매뉴얼 작성 (문제 해결, 모니터링)
- [ ] 아키텍처 다이어그램 작성
- [ ] Docker 이미지 빌드 및 최적화
- [ ] Docker Compose 배포 설정
- [ ] Kubernetes 배포 매니페스트 작성 (선택)
- [ ] CI/CD 파이프라인 구축
  - 자동 테스트
  - 이미지 빌드 및 푸시
- [ ] 수집기 systemd 서비스 파일 작성
- [ ] 모니터링 시스템 자체 모니터링 설정
- [ ] 백업 및 복구 전략 문서화

**Milestone**: 프로덕션 배포 준비 완료

---

## 성능 목표

| 항목 | 목표 |
|------|------|
| 수집기 CPU 오버헤드 | < 5% |
| 수집기 메모리 사용량 | < 100MB |
| 메트릭 수집 지연 | < 1초 |
| 수집 성공률 | > 99.9% |
| API 쿼리 지연 (현재 메트릭) | < 200ms |
| API 쿼리 지연 (24시간 데이터) | < 1초 |
| 대시보드 로딩 시간 | < 2초 |
| 동시 수집기 지원 | 100+ |

---

## 기술 스택

### Collector
- Python 3.9+
- psutil
- requests
- schedule
- PyYAML

### API Server
- FastAPI
- Pydantic
- JWT/API Key 인증
- Uvicorn

### Database
- InfluxDB 2.x (시계열 데이터)
- PostgreSQL (메타데이터, 알림)

### Dashboard
- Grafana

### Alert Manager
- Python (커스텀)
- SMTP (Email)
- Slack API
- Webhooks

### Deployment
- Docker & Docker Compose
- Kubernetes (선택)
- systemd

---

## 리스크 및 대응 전략

| 리스크 | 영향 | 확률 | 대응 전략 |
|--------|------|------|-----------|
| InfluxDB 성능 이슈 | 높음 | 중간 | 초기 부하 테스트, Prometheus 대안 준비 |
| 수집기 안정성 문제 | 높음 | 중간 | 철저한 예외 처리, 자동 재시작 메커니즘 |
| 알림 폭주 | 중간 | 높음 | 중복 제거, Rate limiting 구현 |
| 네트워크 장애 | 높음 | 낮음 | 로컬 버퍼링, 재전송 로직 |
| 보안 취약점 | 높음 | 낮음 | 보안 코드 리뷰, HTTPS/TLS 강제 |

---

## 의존성

- Phase 2는 Phase 1 완료 후 시작
- Phase 3는 Phase 2 완료 후 시작
- 대시보드 개발은 API 개발과 병렬 진행 가능
- 알림 기능은 메트릭 수집 및 저장 기능 완료 필요

---

## 다음 단계

1. 개발 환경 설정 및 프로젝트 구조 생성
2. Week 1 태스크 시작: psutil 기반 CPU 메트릭 수집 모듈 개발
3. 주간 진행 상황 업데이트 (`progress.md`)
